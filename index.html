
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chien-Yi Wang</title>
  
  <meta name="author" content="Chien-Yi Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cover_photo.png">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p style="text-align:center">
                        <name>Chien-Yi Wang</name>
                    </p>
                    <p>
                        I am a Senior Research SDE at <a href="https://news.microsoft.com/apac/2018/01/12/microsoft-launches-artificial-intelligence-research-hub-taiwan/">Microsoft AI R&D Center</a> in Taiwan. I had 6+ years experience specializing in computer vision research, deep learning-based model optimization, and machine learning service integration. My research focus is mainly on face recognition, face anti‑spoofing, and 2D/3D scene understanding. Interested in revolutionizing a machine learning system from the bottom‑up, devising better problem‑solving methods for challenging tasks, and learning new technologies and tools if the need arises.
                    </p>
                    <p>
                        I received my M.S. degree in <a href="https://minghsiehece.usc.edu/">Electrical Engineering</a> from <a href="https://www.usc.edu/">University of Southern California (USC)</a> in 2016 and B.S. degree in <a href="https://web.ee.ntu.edu.tw/">Electrical Engineering</a> from <a href="https://www.ntu.edu.tw/">National Taiwan University (NTU)</a> in 2013, respectivily.  
                    </p>
                    <p style="color:red;">
                        &#11088; We are actively recruiting <strong>full-time research interns</strong> in Face Science Team at Microsoft Taiwan. Apply <a href="https://careers.microsoft.com/students/us/en/job/1101359/Software-Engineer-Intern-Face-Science">here</a> and send an email with your CV to chiwa@microsoft.com with subject “[2022 Research Intern] yourname” to let us know.
                    </p>
                    <p style="text-align:center">
                    <a href="mailto:chienyiwang0922@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=05LW2DcAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/chienyiwang"> LinkedIn </a>&nbsp;/&nbsp;
                    <a href="https://twitter.com/chienyi_wang">Twitter </a>&nbsp;/&nbsp;
                    <a href="https://github.com/chienyiwang">GitHub</a>
                    </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                    <img style="width:100%;max-width:100%" alt="profile photo" src="images/cover_photo.png">
                </td>
              </tr>
            </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision and machine learning.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
        

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fedfr.png" alt="blind-date" width="160" height="160">
                </td>
            <td width="75%" valign="middle">
                <papertitle>FedFR: Joint Optimization Federated Framework for Generic and Personalized Face Recognition</papertitle>
                
                <br>
                <a href="https://jackie840129.github.io/">Chih-Ting Liu*</a>,
                <strong>Chien-Yi Wang*</strong>, 
                <a href="http://media.ee.ntu.edu.tw/member/">Shao-Yi Chien</a>, 
                <a href="http://www.cs.nthu.edu.tw/~lai/">Shang-Hong Lai</a>
                <br>
                <em>36th AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022 &nbsp
                <br>
                <a href="https://chienyiwang.github.io">arXiv</a>
                /
                <a href="https://github.com/jackie840129/FedFR">code (coming soon)</a> 
                <p></p>
                <p>
                In this work, we propose a Federated Learning based framework called FedFR to improve the generic face representation in a privacy-aware manner. Besides, the framework jointly optimizes personalized models for the corresponding clients via the proposed Decoupled Feature Customization module.
                </p>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/wacv2022.png" alt="blind-date" width="160" height="160">
                </td>
            <td width="75%" valign="middle">
                <papertitle>Disentangled Representation with Dual-stage Feature Learning for Face Anti-spoofing</papertitle>
                
                <br>
                <a href="mailto:yuchun@gapp.nthu.edu.tw">Yu-Chun Wang</a>,
                <strong>Chien-Yi Wang</strong>, 
                <a href="http://www.cs.nthu.edu.tw/~lai/">Shang-Hong Lai</a>
                <br>
                <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2022 &nbsp
                <br>
                <a href="https://arxiv.org/abs/2110.09157">arXiv</a>
                <p></p>
                <p>
                    In this work, we propose a novel dual-stage disentangled representation learning method that can efficiently untangle spoof-related features from irrelevant ones. Unlike previous FAS disentanglement works with one-stage architecture, we found that the dual-stage training design can improve the training stability and effectively encode the features to detect unseen attack types.
                </p>
            </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fg2021.png" alt="blind-date" width="160" height="160">
              </td>
          <td width="75%" valign="middle">
              <papertitle>High-Accuracy RGB-D Face Recognition via Segmentation-Aware Face Depth Estimation and Mask-Guided Attention Network</papertitle>
              
              <br>
              <a href="mailto:s108062802@m108.nthu.edu.tw">Meng-Tzu Chiu</a>,
              <a href="mailto:s107062523@m107.nthu.edu.tw">Hsun-Ying Cheng</a>,
              <strong>Chien-Yi Wang</strong>, 
              <a href="http://www.cs.nthu.edu.tw/~lai/">Shang-Hong Lai</a>
              <br>
              <em>IEEE International Conference on Automatic Face and Gesture Recognition (FG)</em>, 2021 &nbsp <p style="color:red;">(Oral Presentation)</p>
              <br>
              <a href="https://chienyiwang.github.io">arXiv</a>
              <p></p>
              <p>
                  We propose to leverage pseudo facial segmentation and depth maps to assist the RGB-D face recognition task. With the multi-modality augmentation, the proposed mask-guided RGB-D recognition model could achieve superior performance on several benchmarks.
              </p>
          </td>
      </tr>
            
        

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Service</heading>
              </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://2020.ieee-iv.org/">Reviewer, IV 2020</a>
                <br><br>              
                <a href="https://accv2020.github.io/">Reviewer, ACCV 2020</a>
                <br><br>
                <a href="https://www.bmvc2020-conference.com/">Reviewer, BMVC 2020</a>
                <br><br>
                <a href="https://www.bmvc2021-virtualconference.com/">Reviewer, BMVC 2021</a>
                <br><br>
                <a href="http://iccv2021.thecvf.com/home">Reviewer, ICCV 2021</a>
                <br><br>
                <a href="https://wacv2022.thecvf.com/home">Reviewer, WACV 2022</a>
                <br><br>
                <a href="https://cvpr2022.thecvf.com/">Reviewer, CVPR 2022</a>
              </td>
            </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                          Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
                  <br>
                  Last updated December 2021.
                      </p>
              </td>
            </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>